{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction of Trace Data\n",
        "\n",
        "content includes:\n",
        "*   overview of this dataset\n",
        "*   three lines of this dataset for preview"
      ],
      "metadata": {
        "id": "Sq4vxuspMMiS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install (optional)\n",
        "if this example requires additional installation, provide the instruction here"
      ],
      "metadata": {
        "id": "n_nsWjd6NFMy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting Started\n",
        "\n"
      ],
      "metadata": {
        "id": "4nR0MrypNiVX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fetch Data\n",
        "provide method to fetch data, may provide a link to download example dataset, may clarify the supported file format"
      ],
      "metadata": {
        "id": "TY8kd0wiP72x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Configuration File\n",
        "### Choice 1. Use example configuration file\n",
        "provide the deault example config file here, may be a link to download the config file\n",
        "\n",
        "\n",
        "### Choice 2. Create customized configuration file\n",
        "#### Step1. Config *processors*\n",
        "explain preprocessor and postprocessor here, provide the processor config format and explain how to fill in\n",
        "\n",
        "\n",
        "```\n",
        "  \"processors\": {\n",
        "    \"preprocessors\": [\n",
        "    ],\n",
        "    \"postprocessors\": [\n",
        "    ]\n",
        "  }\n",
        "```\n",
        "#### Step2. Config *global*\n",
        "provide default global config here, explain ways to change every field\n",
        "```\n",
        "  \"global_config\": {\n",
        "        \"original_data_file\": \"raw.csv\"(change to your file name),\n",
        "        \"overwrite\": true,\n",
        "        \"dataset_type\": \"netflow\",\n",
        "        \"n_chunks\": 1,\n",
        "        \"dp\": false\n",
        "  }\n",
        "```\n",
        "#### Step3. Config *default*\n",
        "explain the ways to config the \"default\"\n",
        "```\n",
        "\"default\": \"single_event_per_row.json\"\n",
        "```\n",
        "#### Step4. Config *pre_post_processor*\n",
        "provide the supported config format as below and go through every field to explain the way to fill in the blank\n",
        "```\n",
        "\"pre_post_processor\": {\n",
        "  \"class\": \"NetsharePrePostProcessor\",\n",
        "          \"config\": {\n",
        "              \"timestamp\": {\n",
        "\n",
        "              },\n",
        "              \"word2vec\": {\n",
        "\n",
        "              },\n",
        "              \"metadata\": [\n",
        "                  {\n",
        "\n",
        "                  }\n",
        "              ],\n",
        "              \"timeseries\": [\n",
        "                {\n",
        "\n",
        "                }\n",
        "              ]\n",
        "          }\n",
        "}\n",
        "\n",
        "```\n",
        "for each field, provide the supported encoding methods and example.\n",
        "example:\n",
        "*   pkt\n",
        "```\n",
        "{\n",
        "    \"column\": \"pkt\",\n",
        "    \"type\": \"float\",\n",
        "    \"normalization\": \"ZERO_ONE\"(optional, choose between \"ZERO_ONE\" and \"MINUS_ONE\"),\n",
        "    \"log1p_norm\": true (optional, choose between true and false)\n",
        "}\n",
        "\n",
        "#### Step5. Config *model*\n",
        "provide default config below, explain the fileds can be changed\n",
        "```\n",
        "\"model\": {\n",
        "        \"class\": \"DoppelGANgerTorchModel\",\n",
        "        \"config\": {\n",
        "            \"batch_size\": 100,\n",
        "            \"sample_len\": [\n",
        "                10\n",
        "            ],\n",
        "            \"sample_len_expand\": true,\n",
        "            \"epochs\": 40,\n",
        "            \"extra_checkpoint_freq\": 1,\n",
        "            \"epoch_checkpoint_freq\": 5\n",
        "        }\n",
        "}\n",
        "    \n",
        "```\n"
      ],
      "metadata": {
        "id": "zHmiYs2_N90K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run with NetShare\n",
        "provide the driver code here,\n",
        "eg.\n",
        "```\n",
        "from netshare.driver import Driver\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    driver = Driver(\n",
        "        working_dir_name='syslog',\n",
        "        dataset_file='syslog.pcap',\n",
        "        config_file='config.json',\n",
        "        local_web_port=8060\n",
        "    )\n",
        "    driver.run()\n",
        "```"
      ],
      "metadata": {
        "id": "xuQaZZBecyYc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Result\n",
        "provide the directory path that contains the synthetic data and result,\n",
        "display the result plots here"
      ],
      "metadata": {
        "id": "CPjq4ePHdyRd"
      }
    }
  ]
}